{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iq6VtLcJRKU",
        "outputId": "425caf6e-e1cc-42c5-fc0e-0ff0a6ccca06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#最初にマウント→メールアドレス選択→許可→「Mounted at /content/drive」を確認\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データの読み込み\n",
        "import csv\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "\n",
        "path = '/content/drive/My Drive/2023_Nishika_aki_train'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename)\n",
        "    li.append(df)\n",
        "\n",
        "df_train_org = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "# 特徴量（絞り込み済）＋目的変数\n",
        "df_train_X_y = df_train_org.iloc[:,[3,7,8,9,10,14,24,27]]\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_1.csv')\n",
        "\n",
        "\n",
        "# ＮＧ値をＯＫ値へ置き換え\n",
        "df_train_X_y = df_train_X_y.replace('1H?1H30', '75')\n",
        "df_train_X_y = df_train_X_y.replace('1H30?2H', '105')\n",
        "df_train_X_y = df_train_X_y.replace('2H?', '120')\n",
        "df_train_X_y = df_train_X_y.replace('30分?60分', '45')\n",
        "df_train_X_y = df_train_X_y.replace('2000㎡以上', '2000')\n",
        "\n",
        "\n",
        "df_train_X_y.columns = ['post','eki','minute','mad','area','born','bai','price']\n",
        "\n",
        "# ＮａＮを空白へ置き換え\n",
        "df_train_X_y['eki'] = df_train_X_y['eki'].fillna('空白')\n",
        "df_train_X_y['mad'] = df_train_X_y['mad'].fillna('空白')\n",
        "df_train_X_y['born'] = df_train_X_y['born'].fillna('空白')\n",
        "\n",
        "# ＮａＮを平均値へ置き換え\n",
        "#★★★うまくできない（課題）\n",
        "#df_train_X_y['minute'] = df_train_X_y['minute'].fillna(df_train_X_y['minute'].mean())\n",
        "#やむを得ず\n",
        "df_train_X_y['minute'] = df_train_X_y['minute'].fillna(11.61216821)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_2.csv')\n",
        "\n",
        "# データは１件もｄｒｏｐされていないことを確認\n",
        "print(df_train_org.shape)\n",
        "print(df_train_X_y.shape)\n",
        "\n",
        "\n",
        "#各特徴量ごとの目的変数の平均をとる\n",
        "post_means = df_train_X_y.groupby('post')['price'].mean()\n",
        "eki_means  = df_train_X_y.groupby('eki')['price'].mean()\n",
        "mad_means  = df_train_X_y.groupby('mad')['price'].mean()\n",
        "born_means = df_train_X_y.groupby('born')['price'].mean()\n",
        "bai_means  = df_train_X_y.groupby('bai')['price'].mean()\n",
        "\n",
        "\n",
        "# 目的変数の平均を特徴量として列を置き換える（ターゲットエンコーディング）\n",
        "df_train_X_y['post'] = df_train_X_y['post'].map(post_means)\n",
        "df_train_X_y['eki']  = df_train_X_y['eki'].map(eki_means)\n",
        "df_train_X_y['mad']  = df_train_X_y['mad'].map(mad_means)\n",
        "df_train_X_y['born'] = df_train_X_y['born'].map(born_means)\n",
        "df_train_X_y['bai']  = df_train_X_y['bai'].map(bai_means)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_3.csv')\n",
        "\n",
        "\n",
        "# 改めて学習データをＸ（特徴量）とｙ（目的変数）へ分割\n",
        "df_train_X = df_train_X_y.iloc[:,:7]\n",
        "df_train_y = df_train_X_y.iloc[:,7]\n",
        "\n",
        "\n",
        "# ランダムフォレストで特徴量の重要度を評価\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "#feat_labels = df_train_X.columns[:7]\n",
        "#forest = RandomForestRegressor(n_estimators=500,\n",
        "#                                random_state=1)\n",
        "#forest.fit(df_train_X, df_train_y)\n",
        "#importances = forest.feature_importances_\n",
        "#indices = np.argsort(importances)[::-1]\n",
        "#for f in range(df_train_X.shape[1]):\n",
        "#    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
        "#                            feat_labels[indices[f]],\n",
        "#                            importances[indices[f]]))\n",
        "#plt.title('Feature importance')\n",
        "#plt.bar(range(df_train_X.shape[1]),\n",
        "#        importances[indices],\n",
        "#        align='center')\n",
        "#\n",
        "#plt.xticks(range(df_train_X.shape[1]),\n",
        "#           feat_labels[indices], rotation=90)\n",
        "#plt.xlim([-1, df_train_X.shape[1]])\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "# 学習データを、訓練データと検証データへ分割する\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    df_train_X, df_train_y, test_size=0.1, random_state=0\n",
        "    )\n",
        "\n",
        "\n",
        "# 評価指標として決定係数（MAE）を使う\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "# 機械学習アルゴリズムにランダムフォレスト回帰を使用\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "# 訓練データに対し層化10分割交差検証を実施する\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "#scores = cross_val_score(estimator=forest,\n",
        "#                         X=X_train,\n",
        "#                         y=y_train,\n",
        "#                         cv=10,\n",
        "#                         scoring='r2',\n",
        "#                         n_jobs=-1)\n",
        "# 10個の決定係数を求め平均と標準偏差を計算する\n",
        "#print(f'CV r2: {scores}')\n",
        "#print(f'CV r2: {np.mean(scores):.3f} '\n",
        "#      f'+/- {np.std(scores):.3f}')\n",
        "# 改めて学習データ全体（訓練データ＋検証データ）でランダムフォレスト回帰を適合\n",
        "#forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators':[150],\n",
        "    'criterion': ['squared_error'],\n",
        "    'max_features':[i for i in range(3, 5)],\n",
        "    'max_depth':[None],\n",
        "}\n",
        "\n",
        "# グリッドサーチ\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs = GridSearchCV(estimator=RandomForestRegressor(),\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='neg_mean_absolute_error',\n",
        "                  refit=True,\n",
        "                  cv=10,\n",
        "                  n_jobs=1)\n",
        "\n",
        "# モデルの最適なパラメータで重み付けを学習\n",
        "gs = gs.fit(X_train, y_train)\n",
        "\n",
        "print(gs.best_score_)\n",
        "\n",
        "# モデルの最適なパラメータ\n",
        "print(gs.best_params_)\n",
        "\n",
        "\n",
        "# 予測\n",
        "y_train_pred = gs.predict(X_train)\n",
        "y_valid_pred = gs.predict(X_valid)\n",
        "\n",
        "# 訓練データ、検証データそれぞれの精度を決定係数（R^2）で評価し、表示する\n",
        "train_mae = mean_absolute_error(y_train,y_train_pred)\n",
        "valid_mae = mean_absolute_error(y_valid,y_valid_pred)\n",
        "\n",
        "print(train_mae)\n",
        "print(valid_mae)\n",
        "\n",
        "\n",
        "# テストデータの読み込み\n",
        "df_test_org = pd.read_csv('/content/drive/My Drive/2023_Nishika_aki_test/test.csv')\n",
        "\n",
        "# 特徴量（絞り込み済）＋目的変数\n",
        "df_test_X = df_test_org.iloc[:,[3,7,8,9,10,14,24]]\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_1.csv')\n",
        "\n",
        "\n",
        "# ＮＧ値をＯＫ値へ置き換え\n",
        "df_test_X = df_test_X.replace('1H?1H30', '75')\n",
        "df_test_X = df_test_X.replace('1H30?2H', '105')\n",
        "df_test_X = df_test_X.replace('2H?', '120')\n",
        "df_test_X = df_test_X.replace('30分?60分', '45')\n",
        "df_test_X = df_test_X.replace('2000㎡以上', '2000')\n",
        "\n",
        "\n",
        "# テストデータにしかない項目名の置き換え\n",
        "df_test_X = df_test_X.replace('伊賀屋', '空白')\n",
        "df_test_X = df_test_X.replace('栗東', '空白')\n",
        "df_test_X = df_test_X.replace('志布志', '空白')\n",
        "df_test_X = df_test_X.replace('小泉町(富山)', '空白')\n",
        "df_test_X = df_test_X.replace('和歌山大学前', '空白')\n",
        "df_test_X = df_test_X.replace('2022年第4四半期', '2021年第4四半期')\n",
        "df_test_X = df_test_X.replace('2023年第1四半期', '2021年第4四半期')\n",
        "\n",
        "\n",
        "df_test_X.columns = ['post','eki','minute','mad','area','born','bai']\n",
        "\n",
        "\n",
        "# ＮａＮを空白へ置き換え\n",
        "df_test_X['eki'] = df_test_X['eki'].fillna('空白')\n",
        "df_test_X['mad'] = df_test_X['mad'].fillna('空白')\n",
        "df_test_X['born'] = df_test_X['born'].fillna('空白')\n",
        "\n",
        "# ＮａＮを平均値へ置き換え\n",
        "#★★★うまくできない（課題）\n",
        "#df_test_X['minute'] = df_test_X['minute'].fillna(df_test_X['minute'].mean())\n",
        "#やむを得ず\n",
        "df_test_X['minute'] = df_test_X['minute'].fillna(11.61216821)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_2.csv')\n",
        "\n",
        "\n",
        "# ターゲットエンコーディングのマッピングをテストデータへの適用\n",
        "df_test_X['post'] = df_test_X['post'].map(post_means)\n",
        "df_test_X['eki']  = df_test_X['eki'].map(eki_means)\n",
        "df_test_X['mad']  = df_test_X['mad'].map(mad_means)\n",
        "df_test_X['born'] = df_test_X['born'].map(born_means)\n",
        "df_test_X['bai']  = df_test_X['bai'].map(bai_means)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_3.csv')\n",
        "\n",
        "\n",
        "# データは１件もｄｒｏｐされていないことを確認\n",
        "print(df_test_org.shape)\n",
        "print(df_test_X.shape)\n",
        "\n",
        "\n",
        "# 予測\n",
        "y_test_pred = gs.predict(df_test_X)\n",
        "\n",
        "# 予測を出力\n",
        "df_y_test_pred = pd.DataFrame(y_test_pred)\n",
        "df_y_test_pred.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/y_test_pred_randomforest.csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiQAivgKNKzS",
        "outputId": "2ee58828-d5f3-4ddd-fb71-1163b9c3908a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e2a2cc4ec88b>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-3-e2a2cc4ec88b>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-3-e2a2cc4ec88b>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-3-e2a2cc4ec88b>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(793377, 28)\n",
            "(793377, 8)\n",
            "-0.09123144869873648\n",
            "{'criterion': 'squared_error', 'max_depth': None, 'max_features': 4, 'n_estimators': 150}\n",
            "0.03483940276708871\n",
            "0.09117568178027191\n",
            "(19271, 27)\n",
            "(19271, 7)\n"
          ]
        }
      ]
    }
  ]
}