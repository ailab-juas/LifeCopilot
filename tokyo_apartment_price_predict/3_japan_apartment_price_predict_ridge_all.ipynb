{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iq6VtLcJRKU",
        "outputId": "d4523b60-4462-4a67-8bf3-ada4d6505ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#最初にマウント→メールアドレス選択→許可→「Mounted at /content/drive」を確認\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データの読み込み\n",
        "import csv\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "\n",
        "path = '/content/drive/My Drive/2023_Nishika_aki_train'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename)\n",
        "    li.append(df)\n",
        "\n",
        "df_train_org = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "# 特徴量（絞り込み済）＋目的変数\n",
        "df_train_X_y = df_train_org.iloc[:,[3,7,8,9,10,14,24,27]]\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_1.csv')\n",
        "\n",
        "\n",
        "# ＮＧ値をＯＫ値へ置き換え\n",
        "df_train_X_y = df_train_X_y.replace('1H?1H30', '75')\n",
        "df_train_X_y = df_train_X_y.replace('1H30?2H', '105')\n",
        "df_train_X_y = df_train_X_y.replace('2H?', '120')\n",
        "df_train_X_y = df_train_X_y.replace('30分?60分', '45')\n",
        "df_train_X_y = df_train_X_y.replace('2000㎡以上', '2000')\n",
        "\n",
        "\n",
        "df_train_X_y.columns = ['post','eki','minute','mad','area','born','bai','price']\n",
        "\n",
        "# ＮａＮを空白へ置き換え\n",
        "df_train_X_y['eki'] = df_train_X_y['eki'].fillna('空白')\n",
        "df_train_X_y['mad'] = df_train_X_y['mad'].fillna('空白')\n",
        "df_train_X_y['born'] = df_train_X_y['born'].fillna('空白')\n",
        "\n",
        "# ＮａＮを平均値へ置き換え\n",
        "#★★★うまくできない（課題）\n",
        "#df_train_X_y['minute'] = df_train_X_y['minute'].fillna(df_train_X_y['minute'].mean())\n",
        "#やむを得ず\n",
        "df_train_X_y['minute'] = df_train_X_y['minute'].fillna(11.61216821)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_2.csv')\n",
        "\n",
        "# データは１件もｄｒｏｐされていないことを確認\n",
        "print(df_train_org.shape)\n",
        "print(df_train_X_y.shape)\n",
        "\n",
        "\n",
        "#各特徴量ごとの目的変数の平均をとる\n",
        "post_means = df_train_X_y.groupby('post')['price'].mean()\n",
        "eki_means  = df_train_X_y.groupby('eki')['price'].mean()\n",
        "mad_means  = df_train_X_y.groupby('mad')['price'].mean()\n",
        "born_means = df_train_X_y.groupby('born')['price'].mean()\n",
        "bai_means  = df_train_X_y.groupby('bai')['price'].mean()\n",
        "\n",
        "\n",
        "# 目的変数の平均を特徴量として列を置き換える（ターゲットエンコーディング）\n",
        "df_train_X_y['post'] = df_train_X_y['post'].map(post_means)\n",
        "df_train_X_y['eki']  = df_train_X_y['eki'].map(eki_means)\n",
        "df_train_X_y['mad']  = df_train_X_y['mad'].map(mad_means)\n",
        "df_train_X_y['born'] = df_train_X_y['born'].map(born_means)\n",
        "df_train_X_y['bai']  = df_train_X_y['bai'].map(bai_means)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_train_X_y.to_csv('/content/drive/My Drive/2023_Nishika_aki_train/all/all_train_X_y_3.csv')\n",
        "\n",
        "\n",
        "# 改めて学習データをＸ（特徴量）とｙ（目的変数）へ分割\n",
        "df_train_X = df_train_X_y.iloc[:,:7]\n",
        "df_train_y = df_train_X_y.iloc[:,7]\n",
        "\n",
        "# ランダムフォレストで特徴量の重要度を評価\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#feat_labels = df_train_X.columns[:7]\n",
        "\n",
        "#forest = RandomForestRegressor(n_estimators=500,\n",
        "#                                random_state=1)\n",
        "\n",
        "#forest.fit(df_train_X, df_train_y)\n",
        "#importances = forest.feature_importances_\n",
        "\n",
        "#indices = np.argsort(importances)[::-1]\n",
        "\n",
        "#for f in range(df_train_X.shape[1]):\n",
        "#    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
        "#                            feat_labels[indices[f]],\n",
        "#                            importances[indices[f]]))\n",
        "\n",
        "#plt.title('Feature importance')\n",
        "#plt.bar(range(df_train_X.shape[1]),\n",
        "#        importances[indices],\n",
        "#        align='center')\n",
        "\n",
        "#plt.xticks(range(df_train_X.shape[1]),\n",
        "#           feat_labels[indices], rotation=90)\n",
        "#plt.xlim([-1, df_train_X.shape[1]])\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "# 学習データを、訓練データと検証データへ分割する\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    df_train_X, df_train_y, test_size=0.1, random_state=0\n",
        "    )\n",
        "\n",
        "\n",
        "# 評価指標として決定係数（R^2）を使う\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# 機械学習アルゴリズム：標準化→ＰＣＡ→リッジ回帰のパイプライン\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipe_ridge = make_pipeline(StandardScaler(),\n",
        "                           PCA(),\n",
        "                           Ridge(random_state=0))\n",
        "\n",
        "\n",
        "# グリッドサーチ\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pca_param_range = [7]\n",
        "ridge_param_range = [ 100.0, 1000.0, 10000.0 ]\n",
        "\n",
        "param_grid = [{'pca__n_components': pca_param_range,\n",
        "               'ridge__alpha': ridge_param_range}]\n",
        "\n",
        "gs = GridSearchCV(estimator=pipe_ridge,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='r2',\n",
        "                  refit=True,\n",
        "                  cv=10,\n",
        "                  n_jobs=-1)\n",
        "\n",
        "# モデルの最適なパラメータで重み付けを学習\n",
        "gs = gs.fit(X_train, y_train)\n",
        "\n",
        "print(gs.best_score_)\n",
        "\n",
        "\n",
        "# モデルの最適なパラメータ\n",
        "print(gs.best_params_)\n",
        "\n",
        "\n",
        "# 予測\n",
        "y_train_pred = gs.predict(X_train)\n",
        "y_valid_pred = gs.predict(X_valid)\n",
        "\n",
        "\n",
        "# 訓練データ、検証データそれぞれの精度を決定係数（R^2）で評価し、表示する\n",
        "train_r2 = r2_score(y_train,y_train_pred)\n",
        "valid_r2 = r2_score(y_valid,y_valid_pred)\n",
        "\n",
        "print(train_r2)\n",
        "print(valid_r2)\n",
        "\n",
        "# テストデータの読み込み\n",
        "df_test_org = pd.read_csv('/content/drive/My Drive/2023_Nishika_aki_test/test.csv')\n",
        "\n",
        "# 特徴量（絞り込み済）＋目的変数\n",
        "df_test_X = df_test_org.iloc[:,[3,7,8,9,10,14,24]]\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_1.csv')\n",
        "\n",
        "\n",
        "# ＮＧ値をＯＫ値へ置き換え\n",
        "df_test_X = df_test_X.replace('1H?1H30', '75')\n",
        "df_test_X = df_test_X.replace('1H30?2H', '105')\n",
        "df_test_X = df_test_X.replace('2H?', '120')\n",
        "df_test_X = df_test_X.replace('30分?60分', '45')\n",
        "df_test_X = df_test_X.replace('2000㎡以上', '2000')\n",
        "\n",
        "\n",
        "# テストデータにしかない項目名の置き換え\n",
        "df_test_X = df_test_X.replace('伊賀屋', '空白')\n",
        "df_test_X = df_test_X.replace('栗東', '空白')\n",
        "df_test_X = df_test_X.replace('志布志', '空白')\n",
        "df_test_X = df_test_X.replace('小泉町(富山)', '空白')\n",
        "df_test_X = df_test_X.replace('和歌山大学前', '空白')\n",
        "df_test_X = df_test_X.replace('2022年第4四半期', '2021年第4四半期')\n",
        "df_test_X = df_test_X.replace('2023年第1四半期', '2021年第4四半期')\n",
        "\n",
        "\n",
        "df_test_X.columns = ['post','eki','minute','mad','area','born','bai']\n",
        "\n",
        "\n",
        "# ＮａＮを空白へ置き換え\n",
        "df_test_X['eki'] = df_test_X['eki'].fillna('空白')\n",
        "df_test_X['mad'] = df_test_X['mad'].fillna('空白')\n",
        "df_test_X['born'] = df_test_X['born'].fillna('空白')\n",
        "\n",
        "# ＮａＮを平均値へ置き換え\n",
        "#★★★うまくできない（課題）\n",
        "#df_test_X['minute'] = df_test_X['minute'].fillna(df_test_X['minute'].mean())\n",
        "#やむを得ず\n",
        "df_test_X['minute'] = df_test_X['minute'].fillna(11.61216821)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_2.csv')\n",
        "\n",
        "\n",
        "# ターゲットエンコーディングのマッピングをテストデータへの適用\n",
        "df_test_X['post'] = df_test_X['post'].map(post_means)\n",
        "df_test_X['eki']  = df_test_X['eki'].map(eki_means)\n",
        "df_test_X['mad']  = df_test_X['mad'].map(mad_means)\n",
        "df_test_X['born'] = df_test_X['born'].map(born_means)\n",
        "df_test_X['bai']  = df_test_X['bai'].map(bai_means)\n",
        "\n",
        "\n",
        "# all出力\n",
        "df_test_X.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/all_test_X_3.csv')\n",
        "\n",
        "\n",
        "# データは１件もｄｒｏｐされていないことを確認\n",
        "print(df_test_org.shape)\n",
        "print(df_test_X.shape)\n",
        "\n",
        "\n",
        "# 予測\n",
        "y_test_pred = gs.predict(df_test_X)\n",
        "\n",
        "# 予測を出力\n",
        "df_y_test_pred = pd.DataFrame(y_test_pred)\n",
        "df_y_test_pred.to_csv('/content/drive/My Drive/2023_Nishika_aki_test/all/y_test_pred_pipe.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiQAivgKNKzS",
        "outputId": "ecb70d43-d19e-4262-c6d9-697a2e77b743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-ef88e5abcb02>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-16-ef88e5abcb02>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-16-ef88e5abcb02>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n",
            "<ipython-input-16-ef88e5abcb02>:14: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filename)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(793377, 28)\n",
            "(793377, 8)\n",
            "0.7199814508328675\n",
            "{'pca__n_components': 7, 'ridge__alpha': 1000.0}\n",
            "0.7201521404169526\n",
            "0.7215470524720058\n",
            "(19271, 27)\n",
            "(19271, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1cHpKE84KWiq"
      }
    }
  ]
}